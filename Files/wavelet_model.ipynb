{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary functions\n",
    "\n",
    "import os\n",
    "import random\n",
    "import Augmentor\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.config.run_functions_eagerly(True)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    "    Activation,\n",
    "    Conv2DTranspose,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from wavetf._wavetf import WaveTFFactory\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, BatchNormalization, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fversaci/WaveTF.git\n",
      "  Cloning https://github.com/fversaci/WaveTF.git to /private/var/folders/pg/zfnz4zn13zlgg_1mt9vl4w900000gn/T/pip-req-build-7yai_p98\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fversaci/WaveTF.git /private/var/folders/pg/zfnz4zn13zlgg_1mt9vl4w900000gn/T/pip-req-build-7yai_p98\n",
      "  Resolved https://github.com/fversaci/WaveTF.git to commit e751efd0bd304e4671b385c80f23c49db314291f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/fversaci/WaveTF.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import layers, Sequential\n",
    "from wavetf import WaveTFFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletBlock(layers.Layer):\n",
    "  def __init__(self, input_channels, wavelet, interpolation, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.input_channels = input_channels\n",
    "    self.wavelet = wavelet\n",
    "    self.interpolation = interpolation\n",
    "    self.wavelet_transform = WaveTFFactory.build(wavelet)\n",
    "    self.cA = [layers.UpSampling2D(size = (2,2), interpolation = interpolation),\n",
    "               layers.DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same'),\n",
    "               layers.BatchNormalization(),\n",
    "               layers.Activation('relu')\n",
    "              ]\n",
    "    self.cH = [layers.UpSampling2D(size = (2,2), interpolation = interpolation),\n",
    "               layers.DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same'),\n",
    "               layers.BatchNormalization(),\n",
    "               layers.Activation('relu')\n",
    "              ]\n",
    "    self.cV = [layers.UpSampling2D(size = (2,2), interpolation = interpolation),\n",
    "               layers.DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same'),\n",
    "               layers.BatchNormalization(),\n",
    "               layers.Activation('relu')\n",
    "              ]\n",
    "    self.cD = [layers.UpSampling2D(size = (2,2), interpolation = interpolation),\n",
    "               layers.DepthwiseConv2D(kernel_size = (3,3), strides = (1,1), padding = 'same'),\n",
    "               layers.BatchNormalization(),\n",
    "               layers.Activation('relu')\n",
    "              ]\n",
    "    self.concat = layers.Concatenate(axis = -1)\n",
    "    self.linear = [layers.Conv2D(filters = input_channels, kernel_size = (1,1), strides = (1,1), padding = 'same'),\n",
    "                   layers.BatchNormalization()\n",
    "                  ]\n",
    "    self.batchnorm = [layers.BatchNormalization(),\n",
    "                      layers.Activation('relu')]\n",
    "\n",
    "  def call(self, inputs):\n",
    "    z = self.wavelet_transform(inputs)\n",
    "\n",
    "    cA = z[:,:,:,:self.input_channels]\n",
    "    cV = z[:,:,:,self.input_channels:2*self.input_channels]\n",
    "    cH = z[:,:,:,2*self.input_channels:3*self.input_channels]\n",
    "    cD = z[:,:,:,3*self.input_channels:]\n",
    "\n",
    "    for layer in self.cA:\n",
    "      cA = layer(cA)\n",
    "    for layer in self.cV:\n",
    "      cV = layer(cV) \n",
    "    for layer in self.cH:\n",
    "      cH = layer(cH) \n",
    "    for layer in self.cD:\n",
    "      cD = layer(cD) \n",
    "    \n",
    "    out = self.concat([cA,cV,cH,cD])\n",
    "\n",
    "    for layer in self.linear:\n",
    "      out = layer(out)\n",
    "    \n",
    "    if inputs.shape[1] != out.shape[1] or inputs.shape[2] != out.shape[2]:\n",
    "        out = tf.image.resize(out, (inputs.shape[1], inputs.shape[2]), method=self.interpolation)\n",
    "    final = out + inputs\n",
    "\n",
    "    for layer in self.batchnorm:\n",
    "      final = layer(final)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mnist_model(wavelet, interpolation):\n",
    "  model = Sequential([layers.Input(shape = (28,28, 1), name = 'input'),\n",
    "                      layers.RandomRotation(factor = 10/360, name = 'random_rotation'),\n",
    "                      layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv2d_1'),\n",
    "                      layers.BatchNormalization(name = 'conv2d_1_bn'),\n",
    "                      layers.Activation('relu', name = 'conv2d_1_relu'),\n",
    "                      WaveletBlock(input_channels = 32, wavelet = wavelet, interpolation = interpolation, name = 'wavelet_block_1'),\n",
    "                      layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding = 'same', name = 'conv2d_2'),\n",
    "                      layers.BatchNormalization(name = 'conv2d_2_bn'),\n",
    "                      layers.Activation('relu', name = 'conv2d_2_relu'),\n",
    "                      WaveletBlock(input_channels = 64, wavelet = wavelet, interpolation = interpolation, name = 'wavelet_block_2'),\n",
    "                      layers.Conv2D(filters = 128, kernel_size = (3,3), strides = (1,1), padding = 'same', name = 'conv2d_3'),\n",
    "                      layers.BatchNormalization(name = 'conv2d_3_bn'),\n",
    "                      layers.Activation('relu', name = 'conv2d_3_relu'),\n",
    "                      layers.GlobalAveragePooling2D(name = 'avgpooling'),\n",
    "                      layers.Dropout(0.4, name = 'dropout'),\n",
    "                      layers.Dense(units = 10, activation = 'softmax', name = 'predictions')],\n",
    "                     name = f'{wavelet}_{interpolation}_model')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mnist_model('haar', 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"haar_nearest_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_rotation (RandomRot  (None, 28, 28, 1)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1_bn (BatchNormaliz  (None, 28, 28, 32)        128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv2d_1_relu (Activation)  (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " wavelet_block_1 (WaveletBl  (None, 28, 28, 32)        1806      \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2_bn (BatchNormaliz  (None, 14, 14, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv2d_2_relu (Activation)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " wavelet_block_2 (WaveletBl  (None, 14, 14, 64)        5646      \n",
      " ock)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3_bn (BatchNormaliz  (None, 14, 14, 128)       512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv2d_3_relu (Activation)  (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " avgpooling (GlobalAverageP  (None, 128)               0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102310 (399.65 KB)\n",
      "Trainable params: 101282 (395.63 KB)\n",
      "Non-trainable params: 1028 (4.02 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 2 classes.\n",
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the directories\n",
    "implant_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Implant Xrays'\n",
    "normal_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Normal Xrays copy'\n",
    "\n",
    "# Define the parameters\n",
    "img_width, img_height = 28, 28\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "\n",
    "# Initialize the ImageDataGenerator for data augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    dtype=np.uint8,\n",
    "    validation_split=0.2  # Adjust the validation split as needed\n",
    ")\n",
    "\n",
    "# Create the generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='training',  # Use 'validation' for validation generator\n",
    "    shuffle=True,  # Shuffle the data\n",
    "    seed=42  # Set seed for reproducibility\n",
    ")\n",
    "\n",
    "# Create the generator for validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale',\n",
    "    subset='validation',\n",
    "    shuffle=False,  # Do not shuffle the data for validation\n",
    "    seed=42  # Set seed for reproducibility\n",
    ")\n",
    "\n",
    "# Convert generators to datasets\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, img_width, img_height, 1], [None])\n",
    ")\n",
    "validation_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, img_width, img_height, 1], [None])\n",
    ")\n",
    "\n",
    "# Prefetch the data for training and validation\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: /Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Implant Xrays/.DS_Store\n",
      "Error loading image: /Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Normal Xrays copy/.DS_Store\n",
      "Error loading image: /Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Implant Xrays/.DS_Store\n",
      "Error loading image: /Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Normal Xrays copy/.DS_Store\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define directories\n",
    "implant_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Implant Xrays'\n",
    "normal_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Normal Xrays copy'\n",
    "\n",
    "# Define parameters\n",
    "img_width, img_height = 28, 28\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def preprocess_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    if img is None:\n",
    "        print(f\"Error loading image: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    img = cv2.resize(img, (img_width, img_height))  # Resize\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "\n",
    "# Function to load images from directory and apply preprocessing\n",
    "def load_images_from_directory(directory):\n",
    "    file_paths = [os.path.join(directory, f) for f in os.listdir(directory)]\n",
    "    images = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        img = preprocess_image(file_path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(1 if 'implant' in file_path.lower() else 0)  # Assuming 'implant' images are positive\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and preprocess training images\n",
    "train_images, train_labels = load_images_from_directory(implant_xrays_dir)\n",
    "normal_train_images, normal_train_labels = load_images_from_directory(normal_xrays_dir)\n",
    "train_images = np.concatenate([train_images, normal_train_images], axis=0)\n",
    "train_labels = np.concatenate([train_labels, normal_train_labels], axis=0)\n",
    "\n",
    "# Shuffle training data\n",
    "shuffle_indices = np.random.permutation(len(train_images))\n",
    "train_images = train_images[shuffle_indices]\n",
    "train_labels = train_labels[shuffle_indices]\n",
    "\n",
    "# Load and preprocess validation images\n",
    "validation_images, validation_labels = load_images_from_directory(implant_xrays_dir)\n",
    "normal_validation_images, normal_validation_labels = load_images_from_directory(normal_xrays_dir)\n",
    "validation_images = np.concatenate([validation_images, normal_validation_images], axis=0)\n",
    "validation_labels = np.concatenate([validation_labels, normal_validation_labels], axis=0)\n",
    "\n",
    "# Convert NumPy arrays to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "\n",
    "# Shuffle and batch train dataset\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch validation dataset\n",
    "validation_dataset = validation_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[202], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.prefetch_op._PrefetchDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an individual image: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract a batch from the generator\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Check the shape of an individual image\n",
    "print(\"Shape of an individual image:\", images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   7,   8,   9,  10,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
       "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
       "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193], dtype=uint8)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(images[0][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_path = \"best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'wavelet_block_1' (type WaveletBlock).\n\nInput 0 of layer \"depthwise_conv2d_130\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (8, 28, 28, 32)\n\nCall arguments received by layer 'wavelet_block_1' (type WaveletBlock):\n  • inputs=tf.Tensor(shape=(8, 28, 28, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[172], line 46\u001b[0m, in \u001b[0;36mWaveletBlock.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     44\u001b[0m   cA \u001b[38;5;241m=\u001b[39m layer(cA)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcV:\n\u001b[0;32m---> 46\u001b[0m   cV \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcV\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcH:\n\u001b[1;32m     48\u001b[0m   cH \u001b[38;5;241m=\u001b[39m layer(cH) \n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'wavelet_block_1' (type WaveletBlock).\n\nInput 0 of layer \"depthwise_conv2d_130\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (8, 28, 28, 32)\n\nCall arguments received by layer 'wavelet_block_1' (type WaveletBlock):\n  • inputs=tf.Tensor(shape=(8, 28, 28, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_dataset,\n",
    "                        initial_epoch = 0,\n",
    "                        epochs = 2, \n",
    "                        validation_data = validation_dataset\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary functions\n",
    "\n",
    "import os\n",
    "import random\n",
    "import Augmentor\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Lambda,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    "    Activation,\n",
    "    Conv2DTranspose,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from wavetf._wavetf import WaveTFFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data_folder = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Normal Xrays copy'\n",
    "implant_data_folder = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Implant Xrays'\n",
    "\n",
    "# Get a list of all files in the data folder\n",
    "normal_files = os.listdir(normal_data_folder)\n",
    "implant_files = os.listdir(implant_data_folder)\n",
    "\n",
    "normal_files = [file for file in normal_files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "implant_files = [file for file in implant_files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "normal_image_list = []\n",
    "for image_file in normal_files:\n",
    "    image_path = os.path.join(normal_data_folder, image_file)\n",
    "    img = Image.open(image_path)\n",
    "    normal_image_list.append(img)\n",
    "\n",
    "implant_image_list = []\n",
    "for image_file in implant_files:\n",
    "    image_path = os.path.join(implant_data_folder, image_file)\n",
    "    img = Image.open(image_path)\n",
    "    implant_image_list.append(img)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_normal = Augmentor.Pipeline('/Users/aditya/Desktop/My Computer/DDP/New/Data/Normal Xrays copy')\n",
    "p_normal.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "p_normal.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)\n",
    "\n",
    "p_normal.sample(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_implant = Augmentor.Pipeline('/Users/aditya/Desktop/My Computer/DDP/New/Data/Implant Xrays')\n",
    "p_implant.rotate(probability=0.7, max_left_rotation=20, max_right_rotation=20)\n",
    "p_implant.zoom(probability=0.5, min_factor=0.8, max_factor=1.6)\n",
    "\n",
    "p_implant.sample(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implant_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Implant Xrays'\n",
    "normal_xrays_dir = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented/Normal Xrays'\n",
    "\n",
    "# Define image dimensions and other parameters\n",
    "img_width, img_height = 150, 150  \n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "img_width, img_height = 18, 18\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers with max pooling\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Flatten the output to feed into dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Adjust the validation split as needed\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'  # Use 'validation' for validation generator\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/aditya/Desktop/My Computer/DDP/New/Data/Augmented',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_path = \"best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = (history.history['loss'])\n",
    "val_loss = (history.history['val_loss'])\n",
    "train_acc = (history.history['accuracy'])\n",
    "val_acc = (history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"Loss Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "\n",
    "plt.legend(['Train_Loss','Val_Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.title(\"Accuracy Graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "\n",
    "plt.legend(['Train_acc','Val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xray_classifier_model_18may_.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/Users/aditya/Desktop/My Computer/DDP/New/Files/xray_classifier_model_18may_.keras')  # Use the actual path to your saved model\n",
    "img_arr = []\n",
    "\n",
    "for i in range(5):\n",
    "    image_path = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Implant Xrays/' + str(i) +'.png'  \n",
    "    img = image.load_img(image_path, target_size=(150, 150))  \n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img /= 255.0  # Normalize the pixel values\n",
    "    img_arr.append(img)\n",
    "\n",
    "for i in range(5):\n",
    "    image_path = '/Users/aditya/Desktop/My Computer/DDP/New/Data/Normal Xrays/' + str(i) +'.png'  \n",
    "    img = image.load_img(image_path, target_size=(150, 150))  \n",
    "    img = image.load_img(image_path, target_size=(150, 150))  \n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img /= 255.0  # Normalize the pixel values\n",
    "    img_arr.append(img)\n",
    "\n",
    "\n",
    "img_arr = random.sample(img_arr, len(img_arr))\n",
    "img_arr = np.array(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Assuming img_arr is a list of 10 images and model is your trained model\n",
    "\n",
    "# Calculate the number of rows and columns for the grid\n",
    "num_images = len(img_arr)\n",
    "num_cols = 2  # Number of columns in the grid\n",
    "num_rows = 2  # Round up division\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 12))\n",
    "\n",
    "for i, img in enumerate(img_arr):\n",
    "    \n",
    "    row_index = i // num_cols\n",
    "    col_index = i % num_cols\n",
    "    \n",
    "    ax = axes[row_index, col_index] if num_rows > 1 else axes[col_index]\n",
    "    ax.imshow(img[0])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "\n",
    "    if prediction[0][0] >= 0.5:\n",
    "        ax.set_title(\"Predicted: Normal X-ray\")\n",
    "    else:\n",
    "        ax.set_title(\"Predicted: Implant X-ray\")\n",
    "    if i == 3: break\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(num_images, num_rows * num_cols):\n",
    "    axes.flatten()[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (150, 150)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "\n",
    "last_conv_layer_name = \"conv2d_11\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(image, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(image)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image\n",
    "# Make model\n",
    "# \n",
    "# Remove last layer's softmax\n",
    "# model.layers[-1].activation = None\n",
    "\n",
    "# Print what the top predicted class is\n",
    "\n",
    "num_images = 2\n",
    "num_cols = 2 # Number of columns in the grid\n",
    "num_rows = 1\n",
    "curr_img = img_arr[7]\n",
    "\n",
    "preds = model.predict(curr_img)\n",
    "# print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
    "\n",
    "# Generate class activation heatmap\n",
    "heatmap = make_gradcam_heatmap(curr_img, model, last_conv_layer_name)\n",
    "\n",
    "# Display heatmap\n",
    "print(heatmap.shape)\n",
    "plt.matshow(heatmap)\n",
    "plt.colorbar()  # Add intensity bar\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(curr_img[0])\n",
    "plt.colorbar()  # Add intensity bar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "print(heatmap.shape)\n",
    "print(curr_img[0].shape)\n",
    "# Plot heatmap1\n",
    "axs[0].matshow(heatmap)\n",
    "axs[0].set_title('Prediction: Implant X-ray')\n",
    "axs[0].grid(False)\n",
    "fig.colorbar(axs[0].matshow(heatmap), ax=axs[0])\n",
    "\n",
    "# Plot heatmap2\n",
    "axs[1].matshow(curr_img[0])\n",
    "axs[1].set_title('Original Image')\n",
    "axs[1].grid(False)\n",
    "fig.colorbar(axs[1].matshow(curr_img[0]), ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
